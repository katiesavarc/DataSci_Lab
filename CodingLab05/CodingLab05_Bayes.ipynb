{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHYS 321 Coding Lab #5: Code Testing and Bayesian Statistics with M&Ms and Radioactivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Coding Lab, our goal is to learn about code testing and to sharpen our Bayesian statistics skills."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian inference with M&Ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: I am indebted to Prof. Gwen Eadie of the University of Toronto, who pioneered a similar M&Ms-based teaching activity while a postdoctoral scholar at the University of Washington)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/M&Ms.jpg\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've consumed M&Ms before, you are probably aware that M&Ms come in a variety of different colours: red, orange, yellow, green, brown, and blue. Exactly how many of each colour one gets in a packet will depend on systematic effects (e.g., at which factory the packet was assembled) and will also have some randomness to it.\n",
    "\n",
    "What we will do today is to answer the following question: __what fraction $b$ of M&Ms do we expect to be blue?__ The goal is to set up the problem as a Bayesian inference problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach might be to open up a packet of M&Ms, and then to just count up the number of blue M&Ms, divide by the total number of M&Ms, and declare that to be your answer. However, such an approach does not account for the fact that there is some randomness to the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that Bayes' theorem says that if we want to infer a parameter $b$, we can take some data $d$ and compute\n",
    "\n",
    "\\begin{equation}\n",
    "p(b|d) \\propto p(d|b) p(b),\n",
    "\\end{equation}\n",
    "where $p(b|d)$ is the *posterior* distribution for the parameter $b$ given the measured data $d$, $p(d|b)$ is the *likelihood* function that tells us the probability of measuring data $d$ given the value $b$, and $p(b)$ is our *prior* belief on the distribution of $b$ before we've taken any data. In this case, our data is the number of blue M&Ms that we find in our packet. After we've collected our data, plugging $d$ into Bayes theorem might give something like this:\n",
    "\n",
    "<div>\n",
    "<img src=\"images/fake_posterior.png\" width=\"400\">\n",
    "</div>\n",
    "Your posterior distribution will not look like this (because I made the plot using fake data). But if this had in fact been the result, it would lead you to conclude that the probability of getting a blue M&M is about $b \\approx 0.6$. The error bar on your estimate of $b$ would be determined by the width of this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__: Let's get started on our Bayesian inference. Write down the likelihood function $p(d|b)$.\n",
    "\n",
    "[Hint: think of $b$ as the fraction of blue M&Ms that are produced at the factory. Now imagine that you work at the factory, and your job is to fill a bag containing $n$ M&Ms. You fill the bag one M&M at a time each time drawing from what is (approximately) an infinite pool of M&Ms in the factory. What is the probability that you end up with $d$ blue M&Ms in a packet containing a total of $n$ M&Ms?]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next step is to decide on a prior distribution. In principle, this can be anything that reflects your belief (your \"best guess\" prior to conducting the experiment). As an example, suppose I am trying to measure the distance $d_\\textrm{gal}$ to a galaxy. I measure $d_\\textrm{meas}$, with an error bar of $\\sigma_m$. If my measurement errors are Gaussian-distributed, my likelihood function is\n",
    "\n",
    "\\begin{equation}\n",
    "p(d_\\textrm{meas} | d_\\textrm{gal}) = \\frac{1}{\\sqrt{2 \\pi \\sigma_m^2}} \\exp \\left[- \\frac{(d_\\textrm{gal} - d_\\textrm{meas})^2}{2 \\sigma_m^2}\\right].\n",
    "\\end{equation}\n",
    "\n",
    "Now suppose that my prior belief on $d_\\textrm{gal}$ is also Gaussian distributed, but centred about some guess $d_\\textrm{guess}$:\n",
    "\n",
    "\\begin{equation}\n",
    "p(d_\\textrm{gal}) = \\frac{1}{\\sqrt{2 \\pi \\sigma_p^2}} \\exp \\left[- \\frac{(d_\\textrm{gal} - d_\\textrm{guess})^2}{2 \\sigma_p^2}\\right],\n",
    "\\end{equation}\n",
    "where $\\sigma_p$ is the uncertainty in my prior knowledge.\n",
    "\n",
    "If I multiply the likelihood by the prior to get the posterior, a little algebraic simplification reveals that\n",
    "\n",
    "\\begin{equation}\n",
    "p(d_\\textrm{gal} | d_\\textrm{meas}) \\propto \\exp \\left[ -\\frac{(d_\\textrm{gal} - \\overline{d})^2}{2 \\overline{\\sigma}^2}\\right],\n",
    "\\end{equation}\n",
    "where $\\overline{d} \\equiv (d_\\textrm{meas}/\\sigma_m^2 + d_\\textrm{guess}/\\sigma_p^2)/(1/\\sigma_p^2 + 1/ \\sigma_m^2)$ and $\\overline{\\sigma} \\equiv (1/\\sigma_p^2 + 1/ \\sigma_m^2)^{-1/2}$. Graphically, this looks like:\n",
    "<div>\n",
    "<img src=\"images/gauss_conjugate.png\" width=\"800\">\n",
    "</div>\n",
    "This illustrates the idea that a Bayesian analysis takes a broad, unconstrained distribution of possibilities and updates it using data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the M&Ms. What's your prior on $b$, the fraction of blue M&Ms in a packet?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Write a function that generates a plot of your prior on $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code and plot goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your (short) discussion of what you picked goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Write some code that will take in your measured data ($d$ blue M&Ms out of a packet containing $n$ M&Ms) and generate plots of the prior, likelihood, and posterior distributions. (Hint: Don't forget that even though we've written a lot of our probability distributions with proportionality signs so far, a proper probability distribution function needs to be normalized so that it integrates to 1!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Time to open up your packet of M&Ms!__ (Not a bad idea at this point to summon one of us to check your work so far)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Open your packet of M&Ms and count the number of blue M&Ms. Plot the prior, likelihood, and posterior distributions. Feel free to eat your data when you are done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Combine data with your partners. There are two ways to do this. One way is to simply combine your datasets into one big dataset and to redo your analysis. Another way to approach this is to use your posterior distribution as the prior for a second round of Bayesian updating. The posterior that comes out of that is then the prior for a third round etc. Do you get the same final posterior with the two methods? Plot the posterior that came from just your data and the posterior from everyone's data in the same figure. What happens as more and more data is added?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code, plots, and discussion here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to The Internet, there are two factories that package M&Ms. One is located in Hackettstown, New Jersey, while the other is located in Cleveland, Tennessee. It turns out that depending on where the M&Ms were packaged, the value of $b$ differs! Here are the colour distributions ([Eadie et al. 2019](https://arxiv.org/abs/1904.11006)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/factorydistributions.png\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__: Based on your posterior distribution for $b$, which factory do you think your M&Ms came from? If you look at the serial number of your packet (it's below where they have the \"best before\" date), you can see which factory your packet came from: if it contains \"CLV\" it came from the Tennesse factory; if it contains \"HKP\", it came from the New Jersey factory. Is your statistical analysis consistent with the serial number? A fascinating thing that I found when buying M&Ms is that there seems to be a third factory that is now manufacturing M&Ms! If you have a packet that is from neither \"CLV\" nor \"HKP\", what can you say about the distributions? Is it close to one of the old factories? Or does it seems like a different distribution altogether?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifying Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, the posterior is everything we want, giving us detailed information about the distribution of possible values of a parameter. If possible, one should report posteriors. However, sometimes someone will ask you \"but if you had to quote a single number and its error bars, what would it be?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One complication with distilling our results into a single number and an error bar is that posterior distributions are often quite complicated. For example, consider the two probability distributions in the picture below:\n",
    "<div>\n",
    "<img src=\"images/multimodal.png\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one's probability distribution is nice and Gaussian like with the black dashed line, the problem is easy. In this case, we get the same answer whether we quote the mean (average value), the median (the middle value if we rank-order all possible values from lowest to highest), or the mode (likeliest value, i.e., the $x$ value where the probability distribution peaks). The error bar $\\Delta x$ is then defined as the standard deviation of the distribution, or---equivalently, for a Gaussian distribution---the width $\\Delta x$ such that  $68\\%$ of the probability resides within $\\pm \\Delta x$ of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the red, non-Gaussian (and multimodal!) probability distribution, the mean ($\\approx 4.2$), the median ($\\approx 4.3$), and the mode ($\\approx 3$). Which one do we quote?\n",
    "\n",
    "There is no \"right answer\" here, and different people do different things. (I guess the only \"right answer\" is to say that if the probability distribution is complicated, one should report the full posterior to make it clear what's going on!) One option is to quote the median and then to examine the *cumulative distribution function* to help us figure out the errors. The cumulative distribution function $P(x)$ for a particular probability distribution $p(x)$ is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "P(x) = \\int_{-\\infty}^x p(x^\\prime) dx^\\prime.\n",
    "\\end{equation}\n",
    "What it tells us is the probability of getting an answer smaller than $x$. For example, if $P(x=6.2) = 0.3$, it means that the $30\\%$ of random draws from the distribution will give values less than $6.2$. We say that the value $6.2$ is the $30$th percentile of the distribution. The median, by definition, is the $50$th percentile of a distribution.\n",
    "\n",
    "In the plot below, we show the cumulative distribution functions for the probability distributions shown above:\n",
    "<div>\n",
    "<img src=\"images/CDFs.png\" width=\"400\">\n",
    "</div>\n",
    "The orange lines show how one can use a cumulative distribution function plot to read off the $16$th percentile, $50$th percentile (i.e., the median), and the $84$th percentile. Why are we interested in these values? Because $84 - 16 = 68$, so between the orange lines, we enclose $68\\%$ of the probability. We can use this to figure out \"the\" error bars on our result. In this case, we quote the median value and then the distance on either side to get to the $16$th and $84$th percentiles. Here, we would say $x = 4.3^{+1.2}_{-1.4}$. (Note the asymmetry of the error bars!) Another way to express our result would be to say that our $68\\%$ credible region spans the range $x\\approx 2.9$ to $x \\approx 5.5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Write a function that takes in your posterior distribution for $b$ from above, and returns the $n\\%$ credible region (e.g., $68\\%$, $95\\%$ etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question__: To what level of credibility (e.g., $68\\%$? $95\\%$?) can you rule out the possibility that your packet of M&Ms came from a different factory to your \"best guess\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Radioactive Source\n",
    "(This problem is adapted from an example from Information Theory, Inference, and Learning Alogrithms by MacKay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the experimental setup depicted below:\n",
    "\n",
    "<div>\n",
    "<img src=\"images/radioactivity.png\" width=\"400\">\n",
    "</div>\n",
    "\n",
    "Unstable radioactive particles are emitted from a source and decay at a distance $x$, a real number that has an exponential probability distribution with characteristic length $\\lambda$, i.e., $p(x|\\lambda) \\propto \\exp( - x / \\lambda)$. Decay events can be observed only if they occur in a window extending from $x=1\\,\\textrm{cm}$ to $x=20\\,\\textrm{cm}$. Decays are observed at $x_1$, $x_2$, $\\dots$, $x_N$. The values of these data points are stored in a file called ``radioactive.dat``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to use Bayesian inference to figure out what $\\lambda$ is. In other words, we would like to find the posterior distribution $p(\\lambda | x_1, x_2, \\dots, x_N)$. Bayes' theorem tells us that\n",
    "\n",
    "\\begin{equation}\n",
    "p(\\lambda | x_1, x_2, \\dots, x_N) \\propto p( x_1, x_2, \\dots, x_N | \\lambda ) p (\\lambda)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with so many Bayesian inference problems, the hardest part is figuring out how to write down the likelihood function $p( x_1, x_2, \\dots, x_N | \\lambda )$. Since the radioactive decays are independent of one another, we can write\n",
    "\n",
    "\\begin{equation}\n",
    "p( x_1, x_2, \\dots, x_N | \\lambda ) = p( x_1| \\lambda )p( x_2| \\lambda )\\dots p( x_N| \\lambda )\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Write down $p(x|\\lambda)$, taking care to make sure that it is a properly normalized probability distribution in $x$. (Recall that we only observe the particles if $x$ is between $1\\,\\textrm{cm}$ and $20\\,\\textrm{cm}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your answer here. This is all algebra, no coding required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: Assuming a uniform prior for $\\lambda$, write some code to generate posterior distributions for $\\lambda$. Make your code flexible enough that you can vary $N$, the number of data points that you read in from ``radioactive.dat``. Plot a series of posterior curves that show how one's knowledge of $\\lambda$ improves as more and more data are taken.\n",
    "\n",
    "(Note 1: ``lambda`` functions are [a thing in Python](https://www.w3schools.com/python/python_lambda.asp). To avoid confusion, it might be good to avoid giving $\\lambda$ the variable name ``lambda`` in your code)\n",
    "\n",
    "(Note 2: Your code may take a few minutes to run. This is normal. There are a lot of exponentials to evaluate, and exponentiating numbers is a fairly slow operation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code and plots here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise__: What is your $95\\%$ credible region for $\\lambda$ after 3 measurements (i.e., using $3$ values of $x$)? After $10$? After $50$? After $99$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your code and answers here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting your work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to push a copy of your completed notebook to your Github repo for marking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
